# Text_Classification

## Q&A

* 한글 + 영문 섞인 데이터 전처링 어떻게? 영어가 대부분이니까 그냥 한글은 삭제 하는게 나으려나?
  * bag of words 기반 모델은 관계 없어

## To do 

* 정확도 측정
  * F1-score - 클래스의 밸런스 관계 없이 모든 클래스 각각이 중요한 경우
  * balanced_accuracy - 각 클래스별로 정확도 측정
* 단어 분석
  * 모든 클래스에 포함되는 단어 제거
  * input 단어 개수 조정
  * 데이터 적은 클래스 뻥튀기 -> 라이브러리 검색 (조교 문의)
* 장비명 통일 (라이브러리 검색 및 조교 문의)
* 노이즈 제거 - 몇자 이하, 특정 코멘트는 제외
* 원인조직 카테고리 추가
* Loss 계산 시 하위 10% 제거하는 라이브러리 (조교 문의)
* 다른 모델 - SVM, bigram, XGBoost

## 

### Oversampling
1. 단순하게 곱하기 n
2. 비중 높은 클래스를 n개로 나누어 n번 학습
3. 새로운 문장 만들기 feat.GPT3


